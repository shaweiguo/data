{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #100: A=[[ 0.07356875]\n",
      " [-0.829471  ]], b=[[0.19327113]], Loss=[0.51288265]\n",
      "Step #200: A=[[ 0.0943661 ]\n",
      " [-0.92226285]], b=[[0.1328711]], Loss=[0.46811098]\n",
      "Step #300: A=[[ 0.08759531]\n",
      " [-1.0077033 ]], b=[[0.07457113]], Loss=[0.39660925]\n",
      "Step #400: A=[[ 0.11287335]\n",
      " [-1.0674685 ]], b=[[0.01127114]], Loss=[0.48001182]\n",
      "Step #500: A=[[ 0.10018191]\n",
      " [-1.1236038 ]], b=[[-0.04552887]], Loss=[0.46034914]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "iris = datasets.load_iris()\n",
    "x_vals = np.array([[x[0], x[3]] for x in iris.data])\n",
    "y_vals = np.array([1 if y==0 else -1 for y in iris.target])\n",
    "\n",
    "train_indices = np.random.choice(len(x_vals), round(len(x_vals)*0.8), replace=False)\n",
    "test_indices = np.array(list(set(range(len(x_vals))) - set(train_indices)))\n",
    "x_vals_train = x_vals[train_indices]\n",
    "x_vals_test = x_vals[test_indices]\n",
    "y_vals_train = y_vals[train_indices]\n",
    "y_vals_test = y_vals[test_indices]\n",
    "\n",
    "batch_size = 100\n",
    "x_data = tf.placeholder(shape=[None, 2], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "A = tf.Variable(tf.random_normal(shape=[2,1]))\n",
    "b = tf.Variable(tf.random_normal(shape=[1,1]))\n",
    "\n",
    "model_output = tf.subtract(tf.matmul(x_data, A), b)\n",
    "\n",
    "l2_norm = tf.reduce_sum(tf.square(A))\n",
    "alpha = tf.constant([0.1])\n",
    "classification_term = tf.reduce_mean(tf.maximum(0., tf.subtract(1., tf.multiply(model_output, y_target))))\n",
    "\n",
    "loss = tf.add(classification_term, tf.multiply(alpha, l2_norm))\n",
    "\n",
    "prediction = tf.sign(model_output)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(prediction, y_target), tf.float32))\n",
    "\n",
    "opt = tf.train.GradientDescentOptimizer(0.01)\n",
    "train_step = opt.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "loss_vec = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "for i in range(500):\n",
    "    rand_index = np.random.choice(len(x_vals_train), size=batch_size)\n",
    "    rand_x = x_vals_train[rand_index]\n",
    "    rand_y = np.transpose([y_vals_train[rand_index]])\n",
    "    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "    temp_loss = sess.run(loss, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "    loss_vec.append(temp_loss)\n",
    "    train_acc_temp = sess.run(accuracy, feed_dict={x_data: x_vals_train, y_target: np.transpose([y_vals_train])})\n",
    "    train_accuracy.append(train_acc_temp)\n",
    "    test_acc_temp = sess.run(accuracy, feed_dict={x_data: x_vals_test, y_target: np.transpose([y_vals_test])})\n",
    "    test_accuracy.append(test_acc_temp)\n",
    "    if (i+1) % 100 == 0:\n",
    "        print('Step #{}: A={}, b={}, Loss={}'.format(str(i+1), str(sess.run(A)), str(sess.run(b)), str(temp_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[a1], [a2]] = sess.run(A)\n",
    "[[b]] = sess.run(b)\n",
    "slope = -a2/a1\n",
    "y_intercept = b/a1\n",
    "x1_vals = [d[1] for d in x_vals]\n",
    "best_fit = []\n",
    "for i in x1_vals:\n",
    "    best_fit.append(slope*i+y_intercept)\n",
    "    setosa_x = [d[1] for i,d in enumerate(x_vals) if y_vals[i]==1]\n",
    "    setosa_y = [d[0] for i,d in enumerate(x_vals) if y_vals[i]==1]\n",
    "    not_setosa_x = [d[1] for i,d in enumerate(x_vals) if y_vals[i]==-1]\n",
    "    not_setosa_y = [d[0] for i,d in enumerate(x_vals) if y_vals[i]==-1]\n",
    "\n",
    "plt.plot(setosa_x, setosa_y, 'o', label='I. setosa')\n",
    "plt.plot(not_setosa_x, not_setosa_y, 'x', label='Non-setosa')\n",
    "plt.plot(x1_vals, best_fit, 'r-', label='Linear Separator', linewidth=3)\n",
    "plt.ylim([0, 10])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Sepal Length vs Petal Width')\n",
    "plt.xlabel('Petal Width')\n",
    "plt.ylabel('Sepal Length')\n",
    "plt.show()\n",
    "plt.plot(train_accuracy, 'k-', label='Training Accuracy')\n",
    "plt.plot(test_accuracy, 'r--', label='Test Accuracy')\n",
    "plt.title('Train and Test Set Accuracies')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "plt.plot(loss_vec, 'k-')\n",
    "plt.title('Loss per Generation')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
