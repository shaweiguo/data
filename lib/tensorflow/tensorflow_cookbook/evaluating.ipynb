{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals = np.random.normal(1, 0.1, 100)\n",
    "y_vals = np.repeat(10., 100)\n",
    "x_data = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 25\n",
    "train_indices = np.random.choice(len(x_vals), round(len(x_vals)*0.8), replace=False)\n",
    "test_indices = np.array(list(set(range(len(x_vals))) - set(train_indices)))\n",
    "x_vals_train = x_vals[train_indices]\n",
    "x_vals_test = x_vals[test_indices]\n",
    "y_vals_train = y_vals[train_indices]\n",
    "y_vals_test = y_vals[test_indices]\n",
    "A = tf.Variable(tf.random_normal(shape=[1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_matmul_A = tf.matmul(x_data, A)\n",
    "loss = tf.reduce_mean(tf.square(x_matmul_A - y_target))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.02)\n",
    "train_step = optimizer.minimize(loss)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79358961, 0.90131517, 1.00066933, 0.97081015, 1.03184319,\n",
       "       0.82542848, 1.02514523, 0.9593399 , 1.13763186, 0.79358961,\n",
       "       0.8475285 , 1.14715237, 0.97065268, 1.01297201, 0.97081015,\n",
       "       1.06236019, 1.03928079, 0.98557601, 0.90131517, 0.87034647,\n",
       "       1.05160195, 0.87034647, 1.01610273, 0.99762057, 0.95701387])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_index = np.random.choice(len(x_vals_train), size=batch_size)\n",
    "x_vals_train[rand_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.79358961, 0.90131517, 1.00066933, 0.97081015, 1.03184319,\n",
       "        0.82542848, 1.02514523, 0.9593399 , 1.13763186, 0.79358961,\n",
       "        0.8475285 , 1.14715237, 0.97065268, 1.01297201, 0.97081015,\n",
       "        1.06236019, 1.03928079, 0.98557601, 0.90131517, 0.87034647,\n",
       "        1.05160195, 0.87034647, 1.01610273, 0.99762057, 0.95701387])]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_x = np.transpose([x_vals_train[rand_index]])\n",
    "rand_x\n",
    "# t = np.array([0.79358961, 0.90131517, 1.00066933, 0.97081015])\n",
    "# np.transpose([t])\n",
    "[x_vals_train[rand_index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #25: A=[[6.5515985]], Loss=13.827074\n",
      "Step #50: A=[[8.730133]], Loss=1.8820121\n",
      "Step #75: A=[[9.522393]], Loss=0.8391925\n",
      "Step #100: A=[[9.833682]], Loss=0.724608\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    rand_index = np.random.choice(len(x_vals_train), size=batch_size)\n",
    "    rand_x = np.transpose([x_vals_train[rand_index]])\n",
    "    rand_y = np.transpose([y_vals_train[rand_index]])\n",
    "    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "    if (i+1) % 25 == 0:\n",
    "        print('Step #{}: A={}, Loss={}'.format(str(i+1), str(sess.run(A)), str(sess.run(loss, feed_dict={x_data: rand_x, y_target: rand_y}))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on test: 1.28, MSE on train: 0.84\n"
     ]
    }
   ],
   "source": [
    "mse_test = sess.run(loss, feed_dict={x_data: np.transpose([x_vals_test]), y_target: np.transpose([y_vals_test])})\n",
    "mse_train = sess.run(loss, feed_dict={x_data: np.transpose([x_vals_train]), y_target: np.transpose([y_vals_train])})\n",
    "print('MSE on test: {}, MSE on train: {}'.format(str(np.round(mse_test, 2)), str(np.round(mse_train, 2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "batch_size = 25\n",
    "x_vals = np.concatenate((np.random.normal(-1, 1, 50), np.random.normal(2, 1, 50)))\n",
    "y_vals = np.concatenate((np.repeat(0., 50), np.repeat(1., 50)))\n",
    "x_data = tf.placeholder(shape=[1, None], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[1, None], dtype=tf.float32)\n",
    "train_indices = np.random.choice(len(x_vals), round(len(x_vals)*0.8), replace=False)\n",
    "test_indices = np.array(list(set(range(len(x_vals))) - set(train_indices)))\n",
    "x_vals_train = x_vals[train_indices]\n",
    "x_vals_test = x_vals[test_indices]\n",
    "y_vals_train = y_vals[train_indices]\n",
    "y_vals_test = y_vals[test_indices]\n",
    "A = tf.Variable(tf.random_normal(mean=10, shape=[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_add_A = tf.add(x_data, A)\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "xentropy = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=x_add_A, labels=y_target))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.05)\n",
    "train_step = optimizer.minimize(xentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #200: A=[5.663674], Loss=2.3566403\n",
      "Step #400: A=[1.3771602], Loss=0.5655485\n",
      "Step #600: A=[-0.0729968], Loss=0.3185306\n",
      "Step #800: A=[-0.397626], Loss=0.23596928\n",
      "Step #1000: A=[-0.4758342], Loss=0.40139493\n",
      "Step #1200: A=[-0.4566848], Loss=0.21102604\n",
      "Step #1400: A=[-0.43522406], Loss=0.34166706\n",
      "Step #1600: A=[-0.4785376], Loss=0.21316364\n",
      "Step #1800: A=[-0.52369076], Loss=0.28938368\n"
     ]
    }
   ],
   "source": [
    "for i in range(1800):\n",
    "    rand_index = np.random.choice(len(x_vals_train), size=batch_size)\n",
    "    rand_x = [x_vals_train[rand_index]]\n",
    "    rand_y = [y_vals_train[rand_index]]\n",
    "    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "    if (i+1) % 200 == 0:\n",
    "        print('Step #{}: A={}, Loss={}'.format(str(i+1), str(sess.run(A)), str(sess.run(xentropy, feed_dict={x_data: rand_x, y_target: rand_y}))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
