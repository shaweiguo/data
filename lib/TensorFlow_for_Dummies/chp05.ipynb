{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"A simple TensorFlow application\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = tf.Variable(tf.random_normal([]))\n",
    "# b = tf.Variable(tf.random_normal([]))\n",
    "# model = tf.add(tf.multiply(x, m), b)\n",
    "# loss = tf.reduce_mean(tf.pow(model - y, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.  9.  8.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "ph = tf.placeholder(tf.float32)\n",
    "vals = np.array([9., 8., 7.])\n",
    "incr = tf.add(ph, 1.)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    res = sess.run(incr, feed_dict={ph: vals})\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Computed result = 0.400000\n",
      "Step 2: Computed result = 0.720000\n",
      "Step 3: Computed result = 0.976000\n",
      "Step 4: Computed result = 1.180800\n",
      "Step 5: Computed result = 1.344640\n",
      "Step 6: Computed result = 1.475712\n",
      "Step 7: Computed result = 1.580570\n",
      "Step 8: Computed result = 1.664456\n",
      "Step 9: Computed result = 1.731565\n",
      "Step 10: Computed result = 1.785252\n",
      "Step 11: Computed result = 1.828201\n",
      "Step 12: Computed result = 1.862561\n",
      "Step 13: Computed result = 1.890049\n",
      "Step 14: Computed result = 1.912039\n",
      "Step 15: Computed result = 1.929631\n",
      "Step 16: Computed result = 1.943705\n",
      "Step 17: Computed result = 1.954964\n",
      "Step 18: Computed result = 1.963971\n",
      "Step 19: Computed result = 1.971177\n",
      "Step 20: Computed result = 1.976941\n",
      "Step 21: Computed result = 1.981553\n",
      "Step 22: Computed result = 1.985243\n",
      "Step 23: Computed result = 1.988194\n",
      "Step 24: Computed result = 1.990555\n",
      "Step 25: Computed result = 1.992444\n",
      "Step 26: Computed result = 1.993955\n",
      "Step 27: Computed result = 1.995164\n",
      "Step 28: Computed result = 1.996131\n",
      "Step 29: Computed result = 1.996905\n",
      "Step 30: Computed result = 1.997524\n",
      "Step 31: Computed result = 1.998019\n",
      "Step 32: Computed result = 1.998415\n",
      "Step 33: Computed result = 1.998732\n",
      "Step 34: Computed result = 1.998986\n",
      "Step 35: Computed result = 1.999189\n",
      "Step 36: Computed result = 1.999351\n",
      "Step 37: Computed result = 1.999481\n",
      "Step 38: Computed result = 1.999585\n",
      "Step 39: Computed result = 1.999668\n",
      "Step 40: Computed result = 1.999734\n",
      "Final x_var: 1.999734\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Define a trainable variable\n",
    "x_var = tf.Variable(0., name='x_result')\n",
    "\n",
    "# Define an untrainable variable to hold the global step\n",
    "step_var = tf.Variable(0, trainable=False)\n",
    "\n",
    "# Express loss in terms of the variable\n",
    "loss = x_var * x_var - 4.0 * x_var + 5.0\n",
    "\n",
    "# Find variable value that minimizes loss\n",
    "learn_rate = 0.1\n",
    "num_epochs = 40\n",
    "optimizer = tf.train.GradientDescentOptimizer(learn_rate).minimize(loss, global_step=step_var)\n",
    "\n",
    "# Initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Create the saver\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Create summary data and FileWriter\n",
    "summary_op = tf.summary.scalar('x', x_var)\n",
    "file_writer = tf.summary.FileWriter('log', graph=tf.get_default_graph())\n",
    "\n",
    "# Launch session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        _, step, result, summary = sess.run([optimizer, step_var, x_var, summary_op])\n",
    "        print('Step %d: Computed result = %f' % (step, result))\n",
    "        \n",
    "        # Print summary data\n",
    "        file_writer.add_summary(summary, global_step=step)\n",
    "        file_writer.flush()\n",
    "    \n",
    "    # Store variable data\n",
    "    saver.save(sess, os.getcwd() + '/output')\n",
    "    print('Final x_var: %f' % sess.run(x_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/sha/dev/ex/data/lib/TensorFlow_for_Dummies/output\n",
      "Variable value:  0.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Load stored graph into current graph\n",
    "    saver = tf.train.import_meta_graph('output.meta')\n",
    "    \n",
    "    # Restore variables into graph\n",
    "    saver.restore(sess, os.getcwd() + '/output')\n",
    "    \n",
    "    # Display value of variable\n",
    "    print('Variable value: ', sess.run('x_result:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.contrib.learn as learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-70a322606ab6>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/sha/anaconda3/envs/p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/sha/anaconda3/envs/p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /home/sha/data/mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/sha/anaconda3/envs/p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /home/sha/data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting /home/sha/data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting /home/sha/data/mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/sha/anaconda3/envs/p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "dset = learn.datasets.mnist.read_data_sets('/home/sha/data/mnist/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images: \t (55000, 784)\n",
      "Validation images: \t (5000, 784)\n",
      "Test images: \t (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print('Training images: \\t', dset.train.images.shape)\n",
    "print('Validation images: \\t', dset.validation.images.shape)\n",
    "print('Test images: \\t', dset.test.images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
